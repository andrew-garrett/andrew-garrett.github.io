<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="shortcut icon" type="image/png" href="../../assets/images/FAVICON.png" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

    <!-- Put your site title here -->
    <title>
        ESE650
    </title>

    <meta name="description" content="UPENN ESE650: Learning in Robotics">
    <!-- Add some coding keywords below, Ex: (React, CSS etc) -->
    <meta name="keywords" content="Andrew Garrett, UPenn, Robotics, Computer Vision, Deep Learning, Machine Learning" />
    <link rel="stylesheet" href="../../index.css" />
</head>

<body>

  <!-- ***** Header ***** -->

    <header class="header" role="banner" id="top">
        <div class="row">
            <nav class="nav" role="navigation">
                <ul class="nav__items">
                  <!-- <li class="nav__item">
                    <a href="../../index.html" class="nav__link">home</a>
                  </li> -->
                </ul>
            </nav>
        </div>
        <div class="header__text-box row">
            <div class="header__text">
                <h1 class="heading-primary">
                    <!-- Project title -->
                    <span>
                        ESE650: Learning in Robotics
                    </span>
                </h1>
                <!-- Put a small paragraph about the project -->
                <p>State Estimation, Planning, and Reinforcement Learning</p>
                <a href="../../index.html#academics" class="btn btn--pink">Go Back</a>
            </div>
        </div>
    </header>

    <main role="main">
        <section>
            <div class="row">
                <p>
                    This course covers three core aspects of robotics: perception, planning, and learning.  These are highly relevant
                    to modern academic research and industrial applications of robotics.  The course is primarily taught by 
                    <a   href="https://pratikac.github.io/">Dr. Pratik Chaudhari</a>, who also:
                    <ul>
                        <li>advised <a href="../projects/project_BOOMBOAT.html">my senior capstone project</a></li>
                        <li>served as the instructor in <a href="./course_ESE546.html">my other favorite course at Penn</a></li>
                        <li>advised my graduate studies</li>
                    </ul>
                </p>

                <h3>State Estimation</h3>

                <blockquote cite="http://asrl.utias.utoronto.ca/~tdb/bib/barfoot_ser17.pdf">
                    <em>
                        "The state of a robot is a set of quantities, such as position, orientation, and velocity, that, if known, fully describe that robot's motion over time...
                        Estimation is the problem of reconstructing the underlying state of a system given a sequence of measurements as well as a prior model of the system."
                    </em>
                    (Barfoot, 2017)
                </blockquote>

                <p>
                    ESE650 begins by developing the probabilistic foundations of algorithms for <b>state estimation</b>, both classical and modern.  This includes the properties
                    of joint, marginal, and conditional probability distributions, expectation and covariance of various types of distributions, Bayes Rule, and Markov Chains.  We
                    can then use these mathematical tools to develop a generalizable model of markovian systems: the <b>Hidden Markov Model (HMM)</b>.  This is a powerful and  fundamental
                    abstraction used to reason about the observations of the state of a markov chain, where observations are treated as random variables.  Mathematically,
                    HMMs are best represented with a <em>transition matrix</em> \( T \) and an <em>emission matrix</em> \( M \).  The entry at (i,j) in a transition matrix, \( T_{i,j} \), describes the probability
                    of <em>transitioning</em> from state \( x = i \) to state \( x = j \).  The entry at (i,j) in an emission matrix, \( M_{i,j} \), describes the probability of making observation \( y = j \) when the system is 
                    in state  \( x = i \).  The HMM framework allows for concise mathematical formulation of many problems in state estimation, such as filtering, smoothing, prediction, decoding,
                    and observation likelihood.
                </p>
                <p>
                    The first homework in ESE650 introduces students to the above topics by implementing a Bayes Filter, an HMM, and 
                    <a   href="https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm">the forward and backward algorithms</a>, 
                    <a   href="https://medium.com/analytics-vidhya/viterbi-algorithm-for-prediction-with-hmm-part-3-of-the-hmm-series-6466ce2f5dc6">Viterbi's Algorithm</a>, and 
                    <a   href="https://medium.com/analytics-vidhya/baum-welch-algorithm-for-training-a-hidden-markov-model-part-2-of-the-hmm-series-d0e393b4fb86">the Baum-Welch Algorithm</a>.
                    This primes students with an understanding of the basics of robot state estimation.  An accurate and precise state-estimation system is one of the first steps, 
                    if not the first step, to deploying robotic systems into the real world.
                </p>

                <figure> 
                    <img class="blog__img" src="../../assets/images/ESE650_HMM.jpg" alt="HMM">
                    <figcaption class="blog__img">
                        Figure 1: A graph representation of an HMM.  The state-space is the weather (raining, cloudy, sunny) and the observation space is the reaction to the weather
                        (happy, sad).  The green arrows define the <em>transition probabilities</em>, while the red arrows define the <em>emission probabilities</em>.
                    </figcaption>
                </figure>

                <p>
                    With a fundamental understanding of state estimation in-hand, we now examine some of the most popular and useful algorithms for state estimation.  
                    A <b>Markov Decision Process (MDP)</b> is a useful formulation for systems where the dynamics or observations cannot be comprehensively or correctly written in the 
                    matrix forms for HMMs.  In such cases, it is convenient to consider noisy dynamics and observation functional models, i.e. \( x_{k+1} = f(x_{k}, u_{k}) \) and 
                    \( y_{k} = g(x_{k}, u_{k}) \).  With this formulation, we introduce the <b>Kalman Filter</b>, which is perhaps the most important algorithm in all of robotics.  
                    The Kalman Filter works under slightly more specific assumptions than the algorithms we looked at previously.  Namely, the basic Kalman Filter is valid under the following conditions:
                    <ul>
                        <li>Linear Dynamics, <em>i.e.</em> \( x_{k+1} = Ax_{k} + Bu_{k} + \epsilon_{k} \) where:
                            <ul>
                                <li>\( x \in \mathbb{R}^{d}, u \in \mathbb{R}^{m} \) are the state and control, respectively</li>
                                <li>\( A \in \mathbb{R}^{d \times d}, B \in \mathbb{R}^{d \times m} \)</li>
                                <li>\( \epsilon \sim \mathcal{N}(0, R), R \in \mathbb{R}^{d \times d} \) is the <b>Gaussian</b> dynamics noise</li>
                            </ul>
                        </li>
                        <li>Linear Observations, <em>i.e.</em> \( y_{k} = Cx_{k} + Du_{k} + \nu_{k} \) where:
                            <ul>
                                <li>\( y \in \mathbb{R}^{p} \) is the observation</li>
                                <li>\( C \in \mathbb{R}^{p \times d}, D \in \mathbb{R}^{p \times m} \)</li>
                                <li>\( \nu \sim \mathcal{N}(0, Q), Q \in \mathbb{R}^{p \times p} \) is the <b>Gaussian</b> observation noise</li>
                            </ul>
                        </li>
                    </ul>
                </p>
                <p>    
                    This essentially constrains the use-cases of the base Kalman Filter to MDPs with linear dynamics models perturbed by gaussian noise, and linear observation models
                    perturbed by gaussian noise.  These assumptions are critical in the formulation of the <em>Kalman Gain</em>.  Notably, the Kalman Filter is optimal for systems that 
                    meet these requirements.  However, nonlinear dynamics models and/or the observation models are typical in robotic systems.  So how do we handle such cases?  Well, we
                    don't; we give up hope and treat the problem as completely intractable and impossible to solve.  Obviously, I am joking here; in fact, we have quite a lot of different
                    approaches to solve such problems.  
                </p>
                <p>
                    The Kalman Filter can be adapted to cases where the dynamics and/or observations are nonlinear, while keeping the assumption that the noise in these models remains Gaussian.
                    There are several adaptations which exist, but the two KF variants we cover in this course are the <b>Extended Kalman Filter (EKF)</b> and the <b>Unscented Kalman Filter (UKF)</b>.
                    The EKF is very straightforward and intuitive, in formulation, application, and explanation.  The core principle of the EKF is to use a Taylor Approximation to linearize the dynamics
                    or observations model at timestep \( k \) about the latest filtered estimates.  After performing this linearization, the system meets the qualifications of the base KF and as such 
                    the KF update equations can be applied without issue.  There are cases, however, where the behavior of the linearized system diverges significantly from the behavior of the true system.
                    Such cases are well-handled by the UKF, which leverages the <b>Unscented Transform (UT)</b> to obtain better estimates of system mean and covariance.  For the sake of brevity, the 
                    UKF uses the UT to construct a set of representative <em>sigma points</em>, and a weighted average is computed to yield mean and covariance estimates of the dynamics and observation models.
                    A more comprehensive understanding of the UKF can be found <a target="_blank" rel="noopener noreferrer" href="http://asrl.utias.utoronto.ca/~tdb/bib/barfoot_ser17.pdf" >in chapter 3 of Barfoot et al.</a>.
                </p>
                <p>
                    The second homework in this course asks students to formulate and implement an EKF from scratch for an unknown/arbitrary system with nonlinear dynamics and observation models, and similarly 
                    implement a UKF for estimating quaternion orientation of a quadrotor from IMU measurements.  This assignment gives students the opportunity to learn by experience (and pain) how these algorithms 
                    work from the ground up, which is highly beneficial for developing a deep understanding of how modern state-estimation systems work.
                </p>

                <figure> 
                    <img class="blog__img" src="../../assets/images/ESE650_UKF.jpg" alt="HMM">
                    <figcaption class="blog__img">
                        Figure 2: A sample plot comparing the UKF estimated orientation to a ground-truth orientation of a quadrotor flying in an indoor environment.  At each timestep, the UKF takes in raw 
                        IMU measurements, calibrates them, and computes running estimates of the mean and covariance for the quaternion orientation.  Personally, I find euler angles
                        make for more understandable plots.
                    </figcaption>
                </figure>

                <p>
                    We now have a strong understanding of state estimation, whether we like it or not.  A natural progression, which this course's curriculum follows, is to examine a class of algorithms
                    called <b>Simultaneous Localization and Mapping (SLAM)</b>.  SLAM is another critical componnt of the robotics stack.  Localization is a special case of state estimation where
                    the state is the robot's pose (position and orientation) and the robot's velocity (oftentimes both linear and angular).  Mapping describes the process of capturing perceptual data such
                    as camera images, lidar ranges, and radar data, and combining it with localization information to create a filtering estimate of the surrounding environment.  In ESE650, we cover
                    a standard method for probabilistic mapping in two dimensions, which can be extended to three dimensions by leveraging efficient data structures such as 
                    <a target="_blank" rel="noopener noreferrer" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html">kD-trees</a> and <a target="_blank" rel="noopener noreferrer" href="https://www.geeksforgeeks.org/octree-insertion-and-searching/">octrees</a>.
                    <a href="../projects/project_TELLOSLAM.html">One of my ongoing personal projects</a> is focused on implementing a SLAM stack for an inexpensive quadrotor platform.
                </p>

                <!-- <p>
                    The third homework in this course spans several different topics, however this is arguably the largest homework in the course, so not all of these topics are exactly coherent with one 
                    another, especially in the way that I have broken down this page.  This homework has students implement a prototypical policy iteration algorithm for a gridworld, a SLAM algorithm for
                    a humanoid robot with lidar, and an hybrid LQR controller for an <a target="_blank" rel="noopener noreferrer" href="http://underactuated.mit.edu/acrobot.html#section1">acrobot</a>.  I found this to be the most interesting, 
                    valuable, and time-consuming assignment in the course, and I take pride in what I was able to accomplish with it.
                </p>

                <figure> 
                    <img class="blog__img" src="../../assets/images/ukf.jpg" alt="HMM">
                    <figcaption class="blog__img">
                        Figure 2: A sample plot comparing the UKF estimated orientation to a ground-truth orientation of a quadrotor flying in an indoor environment.  At each timestep, the UKF takes in raw 
                        IMU measurements, calibrates them, and computes running estimates of the mean and covariance for the quaternion orientation.  Personally, I find euler angles
                        make for more understandable plots.
                    </figcaption>
                </figure>

                <h3>Control</h3>

                <p>
                    The next pillar of robotics which is covered in ESE650 is optimal control.  In my mind, if the robotics stack were to be completely serialized, the outputs generated
                    from state-estimation or SLAM modules would serve as inputs to a planning & control module.  
                </p> -->
            </div>
        </section>
    </main>

  <!-- ***** Footer ***** -->

    <footer role="contentinfo" class="footer">
        <div class="row">
            <!-- Update the links to point to your accounts -->
            <ul class="footer__social-links">
                <li class="footer__social-link-item">
                    <a target="_blank" rel="noopener noreferrer" href="https://www.instagram.com/_.a.n.d.r.3.w._/" title="Link to Instagram Profile">
                        <img src="../../assets/icons/twitter.svg" class="footer__social-image" alt="Instagram">
                    </a>
                </li>
                <li class="footer__social-link-item">
                    <a target="_blank" rel="noopener noreferrer" href="https://github.com/andrew-garrett/" title="Link to Github Profile">
                        <img src="../../assets/icons/github.svg" class="footer__social-image" alt="Github">
                    </a>
                </li>
                <li class="footer__social-link-item">
                    <a target="_blank" rel="noopener noreferrer" href="https://wandb.ai/andrew-garrett" title="Link to Weights and Biases Profile">
                        <img src="../../assets/icons/wandb.svg" class="footer__social-image" alt="Weights and Biases">
                    </a>
                </li>
                <li class="footer__social-link-item">
                    <a target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/andrew-garrett-939a94143/">
                        <img src="../../assets/icons/linkedin.svg" title="Link to Linkedin Profile" class="footer__social-image" alt="Linkedin">
                    </a>
                </li>
            </ul>

            <!-- If you give me some credit by keeping the below paragraph, will be huge for me ðŸ˜Š Thanks. -->
            <p>
                &copy; 2023 - Template designed & developed by <a target="_blank" rel="noopener noreferrer" href="https://nisar.dev" class="link">Nisar</a>.
            </p>
            <div class="footer__github-buttons">
                <iframe
                    src="https://ghbtns.com/github-btn.html?user=nisarhassan12&repo=portfolio-template&type=watch&count=true"
                    frameborder="0" scrolling="0" width="170" height="20" title="Watch Portfolio Template on GitHub">
                </iframe>
            </div>
        </div>
    </footer>

    <a href="#top" class="back-to-top" title="Back to Top">
        <img src="../../assets/icons/arrow-up.svg" alt="Back to Top" class="back-to-top__image"/>
    </a>
    <script src="../../index.js"></script>
</body>

</html>